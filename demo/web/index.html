<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <title>Live Context ASR Demo</title>
  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      margin: 16px;
      background: #0b0c10;
      color: #e5e5e5;
    }

    h1 {
      margin-top: 0;
      font-size: 20px;
    }

    .controls {
      margin-bottom: 12px;
    }

    button {
      padding: 6px 12px;
      margin-right: 8px;
      border-radius: 4px;
      border: none;
      cursor: pointer;
      background: #1f4068;
      color: #fff;
    }

    button:disabled {
      opacity: 0.6;
      cursor: not-allowed;
    }

    #status {
      display: inline-block;
      margin-left: 8px;
      font-size: 13px;
    }

    .status-pill {
      display: inline-block;
      padding: 2px 8px;
      border-radius: 999px;
      font-size: 11px;
      margin-left: 4px;
    }

    .status-ok {
      background: #145c32;
      color: #c8f7c5;
    }

    .status-bad {
      background: #6b1b25;
      color: #f8c6ce;
    }

    .layout {
      display: grid;
      grid-template-columns: 2fr 1.2fr;
      grid-gap: 12px;
      margin-top: 12px;
    }

    .panel {
      border-radius: 6px;
      padding: 8px;
      background: #141722;
      border: 1px solid #222632;
      overflow: hidden;
    }

    .panel h2 {
      margin: 0 0 6px 0;
      font-size: 14px;
      text-transform: uppercase;
      letter-spacing: 0.06em;
      color: #a0a7bd;
    }

    #transcript {
      font-size: 14px;
      line-height: 1.5;
      white-space: pre-wrap;
      word-wrap: break-word;
      max-height: 420px;
      overflow-y: auto;
    }

    .utt-line {
      display: block;
      margin-bottom: 4px;
    }

    .utt-final {
      color: #e5e5e5;
    }

    .utt-partial {
      color: #c0c6df;
    }

    .utt-meta {
      font-size: 11px;
      color: #7b8198;
      margin-right: 4px;
    }

    #finalList {
      font-size: 13px;
      line-height: 1.4;
      max-height: 200px;
      overflow-y: auto;
    }

    .final-item {
      margin-bottom: 6px;
      padding-bottom: 4px;
      border-bottom: 1px solid #222632;
    }

    .final-meta {
      font-size: 11px;
      color: #9aa0b8;
      margin-bottom: 2px;
    }

    .tag {
      display: inline-block;
      padding: 1px 6px;
      border-radius: 999px;
      font-size: 10px;
      margin-right: 4px;
    }

    .tag-ready {
      background: #145c32;
      color: #c8f7c5;
    }

    .tag-skip {
      background: #3a3f4f;
      color: #c0c4d4;
    }

    #log {
      font-family: "SF Mono", Menlo, Consolas, monospace;
      font-size: 11px;
      background: #050608;
      color: #c4c4c4;
      padding: 6px;
      border-radius: 4px;
      max-height: 260px;
      overflow-y: auto;
      white-space: pre-wrap;
    }
  </style>
</head>
<body>
  <h1>Live Context – Screen Share ASR</h1>

  <div class="controls">
    <button id="connectBtn">Connect WS</button>
    <button id="shareBtn" disabled>Start Screen Share (with audio)</button>
    <span id="status">
      WS: <span id="wsStatusPill" class="status-pill status-bad">DISCONNECTED</span>
    </span>
  </div>

  <div class="layout">
    <!-- Left: evolving transcript + final list -->
    <div class="panel">
      <h2>Transcript (live)</h2>
      <div id="transcript">– waiting for audio –</div>

      <h2 style="margin-top: 10px;">Final Utterances</h2>
      <div id="finalList"></div>
    </div>

    <!-- Right: debug log -->
    <div class="panel">
      <h2>Debug Log</h2>
      <div id="log"></div>
    </div>
  </div>

  <script>
    let ws = null;
    let audioContext = null;
    let processor = null;

    const wsStatusPill = document.getElementById("wsStatusPill");
    const transcriptEl = document.getElementById("transcript");
    const finalListEl = document.getElementById("finalList");
    const logEl = document.getElementById("log");

    // utteranceId -> { id, speaker, tStart, tEnd, finalText, latestText, isFinal, quality }
    const utterances = new Map();
    const renderedFinalIds = new Set();

    function log(msg) {
      console.log(msg);
      logEl.textContent += msg + "\n";
      logEl.scrollTop = logEl.scrollHeight;
    }

    function setWsStatus(connected) {
      if (connected) {
        wsStatusPill.textContent = "CONNECTED";
        wsStatusPill.classList.remove("status-bad");
        wsStatusPill.classList.add("status-ok");
      } else {
        wsStatusPill.textContent = "DISCONNECTED";
        wsStatusPill.classList.remove("status-ok");
        wsStatusPill.classList.add("status-bad");
      }
    }

    function formatSeconds(sec) {
      if (sec === undefined || isNaN(sec)) return "??:??";
      const s = Math.max(0, Math.floor(sec));
      const m = Math.floor(s / 60);
      const r = s % 60;
      return `${m.toString().padStart(2, "0")}:${r.toString().padStart(2, "0")}`;
    }

    function getTextPayload(msg) {
      if (!msg) return "";
      if (typeof msg.text === "string" && msg.text.length > 0) return msg.text;
      if (typeof msg.raw_text === "string" && msg.raw_text.length > 0) return msg.raw_text;
      return "";
    }

    function withTrailingSpace(text) {
      if (!text) return "";
      return text.endsWith(" ") ? text : `${text} `;
    }

    function resetSessionState() {
      utterances.clear();
      renderedFinalIds.clear();
      finalListEl.innerHTML = "";
      transcriptEl.textContent = "– waiting for audio –";
    }

    function upsertUtteranceFromPartial(msg) {
      const id = msg.utterance_id;
      const q = msg.quality || {};
      const existing = utterances.get(id) || {
        id,
        speaker: msg.speaker || "UNKNOWN",
        tStart: msg.t_start ?? 0,
        tEnd: msg.t_end ?? 0,
        finalText: null,
        latestText: "",
        isFinal: false,
        quality: q
      };

      existing.speaker = msg.speaker || existing.speaker || "UNKNOWN";
      existing.latestText = getTextPayload(msg);
      existing.tStart = (msg.t_start !== undefined) ? msg.t_start : existing.tStart;
      existing.tEnd = (msg.t_end !== undefined) ? msg.t_end : existing.tEnd;
      existing.isFinal = false;
      existing.quality = q;
      utterances.set(id, existing);
    }

    function upsertUtteranceFromFinal(msg) {
      const id = msg.utterance_id;
      const q = msg.quality || {};
      const existing = utterances.get(id) || {
        id,
        speaker: msg.speaker || "UNKNOWN",
        tStart: msg.t_start ?? 0,
        tEnd: msg.t_end ?? 0,
        finalText: null,
        latestText: "",
        isFinal: false,
        quality: q
      };

      existing.speaker = msg.speaker || existing.speaker || "UNKNOWN";
      const finalText = getTextPayload(msg);
      existing.finalText = finalText;
      existing.latestText = finalText;
      existing.tStart = (msg.t_start !== undefined) ? msg.t_start : existing.tStart;
      existing.tEnd = (msg.t_end !== undefined) ? msg.t_end : existing.tEnd;
      existing.isFinal = true;
      existing.quality = q;
      utterances.set(id, existing);
    }

    // Continuous transcript: all finals rendered as stable text + a single live partial tail.
    function renderTranscript() {
      if (utterances.size === 0) {
        transcriptEl.textContent = "– waiting for audio –";
        return;
      }

      const items = Array.from(utterances.values())
        .sort((a, b) => (a.tStart ?? 0) - (b.tStart ?? 0));

      const finalUtterances = [];
      let currentPartial = null;

      for (const item of items) {
        const hasText = (item.finalText && item.finalText.length > 0) || (item.latestText && item.latestText.length > 0);
        if (!hasText) continue;

        if (item.isFinal && item.finalText) {
          finalUtterances.push(item);
        } else if (!item.isFinal && item.latestText) {
          if (!currentPartial || (item.tStart ?? 0) >= (currentPartial.tStart ?? 0)) {
            currentPartial = item;
          }
        }
      }

      if (finalUtterances.length === 0 && !currentPartial) {
        transcriptEl.textContent = "– waiting for audio –";
        return;
      }

      transcriptEl.innerHTML = "";
      const fragment = document.createDocumentFragment();

      // Group consecutive final utterances by speaker so each speaker turn
      // renders as a single line of text.
      const groupedFinals = [];
      for (const u of finalUtterances) {
        const speakerKey = u.speaker || "UNKNOWN";
        const text = u.finalText || u.latestText || "";

        if (groupedFinals.length === 0 || groupedFinals[groupedFinals.length - 1].speaker !== speakerKey) {
          groupedFinals.push({
            speaker: speakerKey,
            tStart: u.tStart,
            tEnd: u.tEnd,
            utteranceIds: [u.id],
            texts: [text],
          });
        } else {
          const last = groupedFinals[groupedFinals.length - 1];
          last.utteranceIds.push(u.id);
          last.texts.push(text);
          last.tEnd = u.tEnd;
        }
      }

      for (const group of groupedFinals) {
        const line = document.createElement("div");
        line.className = "utt-line utt-final";

        const speakerLabel = group.speaker && group.speaker !== "UNKNOWN"
          ? `${group.speaker.toUpperCase()}: `
          : "";

        const combinedText = withTrailingSpace(group.texts.join(" ").trim());
        line.textContent = speakerLabel + combinedText;
        line.dataset.utteranceIds = group.utteranceIds.join(",");
        line.dataset.speaker = group.speaker || "";
        line.dataset.tStart = group.tStart;
        line.dataset.tEnd = group.tEnd;
        fragment.appendChild(line);
      }

      if (currentPartial) {
        const line = document.createElement("div");
        line.className = "utt-line utt-partial";

        const speakerLabel = currentPartial.speaker && currentPartial.speaker !== "UNKNOWN"
          ? `${currentPartial.speaker.toUpperCase()}: `
          : "";

        line.textContent = speakerLabel + (currentPartial.latestText || "");
        line.dataset.utteranceId = currentPartial.id;
        line.dataset.speaker = currentPartial.speaker || "";
        line.dataset.tStart = currentPartial.tStart;
        line.dataset.tEnd = currentPartial.tEnd;
        line.dataset.confidence = currentPartial.quality?.avg_confidence ?? "";
        line.dataset.wordCount = currentPartial.quality?.word_count ?? "";
        line.dataset.langchainReady = currentPartial.quality?.langchain_ready ?? "false";
        fragment.appendChild(line);
      }

      transcriptEl.appendChild(fragment);
      transcriptEl.scrollTop = transcriptEl.scrollHeight;
    }

    function appendFinalListItem(u) {
      if (!u || !u.isFinal || renderedFinalIds.has(u.id)) {
        return;
      }

      const q = u.quality || {};
      const wc = q.word_count ?? "?";
      const conf = q.avg_confidence !== undefined ? q.avg_confidence.toFixed(2) : "?";
      const ready = q.langchain_ready ? "READY" : "skip";
      const tLabel = formatSeconds(u.tStart);

      const div = document.createElement("div");
      div.className = "final-item";

      const meta = document.createElement("div");
      meta.className = "final-meta";

      const tag = document.createElement("span");
      tag.className = "tag " + (q.langchain_ready ? "tag-ready" : "tag-skip");
      tag.textContent = ready;

      meta.appendChild(tag);
      meta.appendChild(document.createTextNode(
        ` utt=${u.id} • spk=${u.speaker || "UNKNOWN"} • t=${tLabel} • wc=${wc} • conf=${conf}`
      ));

      const textDiv = document.createElement("div");
      textDiv.textContent = u.finalText || u.latestText || "";

      div.appendChild(meta);
      div.appendChild(textDiv);

      finalListEl.appendChild(div);
      finalListEl.scrollTop = finalListEl.scrollHeight;
      renderedFinalIds.add(u.id);
    }

    document.getElementById("connectBtn").onclick = () => {
      if (ws && ws.readyState === WebSocket.OPEN) {
        log("WebSocket already connected");
        return;
      }

      ws = new WebSocket("ws://localhost:8765");
      ws.binaryType = "arraybuffer";

      ws.onopen = () => {
        log("✅ WebSocket connected");
        setWsStatus(true);
        document.getElementById("shareBtn").disabled = false;
      };

      ws.onclose = () => {
        log("❌ WebSocket closed");
        setWsStatus(false);
        document.getElementById("shareBtn").disabled = true;
      };

      ws.onerror = (e) => {
        log("❌ WebSocket error");
        console.error(e);
      };

      ws.onmessage = (e) => {
        try {
          const msg = JSON.parse(e.data);

          if (msg.type === "partial_utterance") {
            upsertUtteranceFromPartial(msg);
            renderTranscript();
          } else if (msg.type === "final_utterance") {
            upsertUtteranceFromFinal(msg);
            renderTranscript();
            appendFinalListItem(utterances.get(msg.utterance_id));
          } else if (msg.type === "session_started") {
            resetSessionState();
            log("Session started: " + JSON.stringify(msg.config));
          } else if (msg.type === "session_stopped") {
            log("Session stopped");
          } else if (msg.type === "context_window_ready") {
            const q = msg.quality || {};
            const wc = q.word_count ?? "?";
            const conf = q.avg_confidence !== undefined ? q.avg_confidence.toFixed(2) : "?";
            log(`[CTX][${msg.window_id}] wc=${wc} conf=${conf}\n${msg.text}`);
          } else {
            log("Event: " + e.data);
          }
        } catch (err) {
          // Non-JSON fallback
          log("Server message: " + e.data);
        }
      };
    };

    document.getElementById("shareBtn").onclick = async () => {
      if (!ws || ws.readyState !== WebSocket.OPEN) {
        log("WebSocket not connected");
        return;
      }

      let stream;
      try {
        stream = await navigator.mediaDevices.getDisplayMedia({
          video: true,
          audio: true
        });
      } catch (err) {
        log("Failed to start screen share: " + err);
        return;
      }

      log("Screen share started");

      // Audio pipeline in browser → PCM16 → WS
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);

      const bufferSize = 4096;
      const inputChannels = 1;
      const outputChannels = 1;
      processor = audioContext.createScriptProcessor(bufferSize, inputChannels, outputChannels);

      processor.onaudioprocess = (audioEvent) => {
        const inputBuffer = audioEvent.inputBuffer;
        const channelData = inputBuffer.getChannelData(0); // Float32Array [-1, 1]

        const pcm16 = floatTo16BitPCM(channelData);

        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send(pcm16.buffer);
        }
      };

      source.connect(processor);
      processor.connect(audioContext.destination);

      log("Streaming audio to server...");
    };

    function floatTo16BitPCM(float32Array) {
      const len = float32Array.length;
      const pcm16 = new Int16Array(len);
      for (let i = 0; i < len; i++) {
        let s = float32Array[i];
        s = Math.max(-1, Math.min(1, s));
        pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
      }
      return pcm16;
    }
  </script>
</body>
</html>
